{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "## This is the three-linear layer model that was originally shown to us during our meeting."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"uKzifCZnGzxZsYYuBu2E2T"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE, mean_absolute_percentage_error as MAPE"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"RHbPuaaIz7Qhk0CCNfEPCn"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # m.weight.data.uniform_(0.0,1.0)\n",
    "        m.weight.data.normal_(0.0,1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain(\"linear\"))\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def MAPELoss(output, target):\n",
    "    loss = (torch.abs(output - target) \/ torch.abs(target)).mean()\n",
    "    return loss\n",
    "\n",
    "# # convert a df to tensor to be used in pytorch\n",
    "# def df_to_tensor(df):\n",
    "#     device = get_device()\n",
    "#     return torch.from_numpy(df.values).float().to(device)"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"UyV3xZySLPiLhGXN0ObgIq"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "batch_size = 2048\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.001"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"dUI5o5ZRmle7O4yPzdwGjM"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "data_path = \"\/data\/workspace_files\/\"\n",
    "vols = np.load(data_path + \"12_12_sample_lognormal_vol.npy\")\n",
    "names = [\"S\", \"T\", \"V_atm\", \"Beta\", \"Rho\", \"Volvol\", \"K\"]\n",
    "\n",
    "multiindex = pd.MultiIndex.from_product([range(i) for i in vols.shape],\n",
    "                                        names=names\n",
    "                                       )\n",
    "full_df = pd.DataFrame(vols.reshape((-1,1)), index=multiindex, columns=[\"Lognormal_vol\"]).reset_index()\n",
    "print(full_df.shape)\n",
    "\n",
    "# get features:\n",
    "data_ranges = {'S': np.linspace(0.005+0.0, 0.07+0.03, num=12),\n",
    "               'T': np.linspace(0.5, 20., num=5),\n",
    "               'V_atm': np.linspace(0.001, 0.015, num=3),\n",
    "               'Beta': np.linspace(0.1, 0.7, num=2),\n",
    "               'Rho': np.linspace(-0.4, 0.4, num=3),\n",
    "               'Volvol': np.linspace(0.0001, 0.5, num=5),\n",
    "               'K': np.linspace(0.005+0.0, 0.07+0.03, num=12)\n",
    "              }\n",
    "\n",
    "for key in data_ranges.keys():\n",
    "    full_df[key] = data_ranges[key][full_df[key]]\n",
    "\n",
    "test_df = full_df.sample(frac=0.6, replace=False, random_state=1)\n",
    "train_df = full_df.drop(test_df.index) # 19440 for 30%\n",
    "\n",
    "train_target = torch.tensor(train_df['Lognormal_vol'].values.astype(np.float32))\n",
    "train_features = torch.tensor(train_df.drop('Lognormal_vol', axis = 1).values.astype(np.float32)) \n",
    "train_tensor = data_utils.TensorDataset(train_features, train_target)\n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "test_target = torch.tensor(test_df['Lognormal_vol'].values.astype(np.float32))\n",
    "test_features = torch.tensor(test_df.drop('Lognormal_vol', axis = 1).values.astype(np.float32)) "
   ],
   "execution_count":4,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "(64800, 8)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"hHqBtabLo5eJVfOrYI2RPT"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## MAPELoss"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"rNPYYAI9iChttbuBy9s0LP"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def create_model():\n",
    "    model = torch.nn.Sequential(nn.Linear(7, 16),\n",
    "                            nn.Linear(16,32),\n",
    "                            nn.Linear(32, 64),\n",
    "                            nn.Sigmoid(),\n",
    "                            nn.Linear(64,10),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(10,1),\n",
    "                            nn.Sigmoid()\n",
    "                            )\n",
    "    return model\n",
    "\n",
    "model_params = {\n",
    "    'train_loader': train_loader,\n",
    "    'test_features': test_features,\n",
    "    'test_target': test_target,\n",
    "    'create_model': create_model,\n",
    "    'n_epochs': n_epochs,\n",
    "    'criterion': MAPELoss,\n",
    "    'init_fn': weights_init\n",
    "}"
   ],
   "execution_count":5,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"wXkQRInQHOjfm8KuI1PXIF"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Stability Analysis\n",
    "\n",
    "def run_n(n, model_params):\n",
    "    # model_params['model'] # do it just in case\n",
    "    runs_mae = []\n",
    "    runs_mse = []\n",
    "    runs_mape = []\n",
    "    for run in range(n):\n",
    "        print(f\"run {run}\")\n",
    "        model = create_model()\n",
    "        model.apply(model_params['init_fn'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(model_params['n_epochs']):  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            # print(type(running_loss))\n",
    "            for i, data in enumerate(model_params['train_loader'], 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = model_params['criterion'](np.squeeze(outputs), labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "            if epoch % 10 == 9:\n",
    "                print(f\"epoch {epoch} out of {model_params['n_epochs']} loss: {running_loss}\")\n",
    "        # print(f'Finished Training run {run}')\n",
    "        pred = model(model_params['test_features'])\n",
    "        runs_mae.append(MAE(np.squeeze(pred.cpu().detach().numpy()), model_params['test_target']))\n",
    "        runs_mse.append(MSE(np.squeeze(pred.cpu().detach().numpy()), model_params['test_target']))\n",
    "        runs_mape.append(MAPE(np.squeeze(pred.cpu().detach().numpy()), model_params['test_target']))\n",
    "        \n",
    "    print(f\"mae mean: {np.mean(runs_mae)} std: {np.std(runs_mae)}\")\n",
    "    print(f\"mse mean: {np.mean(runs_mse)} std: {np.std(runs_mse)}\")\n",
    "    print(f\"mape mean: {np.mean(runs_mape)} std: {np.std(runs_mape)}\")"
   ],
   "execution_count":6,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"7xRXhcwZ0nABceQeAHBzxq"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "run_n(5, model_params)"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "run 0\n",
      "epoch 9 out of 1000 loss: 12.014709234237671\n",
      "epoch 19 out of 1000 loss: 9.592508673667908\n",
      "epoch 29 out of 1000 loss: 7.234126269817352\n",
      "epoch 39 out of 1000 loss: 6.452080935239792\n",
      "epoch 49 out of 1000 loss: 6.101460695266724\n",
      "epoch 59 out of 1000 loss: 5.779362052679062\n",
      "epoch 69 out of 1000 loss: 2.3583804294466972\n",
      "epoch 79 out of 1000 loss: 1.3025216311216354\n",
      "epoch 89 out of 1000 loss: 1.1423590071499348\n",
      "epoch 99 out of 1000 loss: 0.9773812629282475\n",
      "epoch 109 out of 1000 loss: 1.0189076084643602\n",
      "epoch 119 out of 1000 loss: 0.7992177307605743\n",
      "epoch 129 out of 1000 loss: 0.6552054230123758\n",
      "epoch 139 out of 1000 loss: 0.7859694128856063\n",
      "epoch 149 out of 1000 loss: 0.5434000706300139\n",
      "epoch 159 out of 1000 loss: 0.6618283363059163\n",
      "epoch 169 out of 1000 loss: 0.5252871382981539\n",
      "epoch 179 out of 1000 loss: 0.446321826428175\n",
      "epoch 189 out of 1000 loss: 0.4682282358407974\n",
      "epoch 199 out of 1000 loss: 0.7152353739365935\n",
      "epoch 209 out of 1000 loss: 0.46171247586607933\n",
      "epoch 219 out of 1000 loss: 0.5028782775625587\n",
      "epoch 229 out of 1000 loss: 0.390199719928205\n",
      "epoch 239 out of 1000 loss: 0.4604157619178295\n",
      "epoch 249 out of 1000 loss: 0.5764836352318525\n",
      "epoch 259 out of 1000 loss: 0.6715020053088665\n",
      "epoch 269 out of 1000 loss: 0.6631818879395723\n",
      "epoch 279 out of 1000 loss: 0.6626535914838314\n",
      "epoch 289 out of 1000 loss: 0.4620154853910208\n",
      "epoch 299 out of 1000 loss: 0.6253674607723951\n",
      "epoch 309 out of 1000 loss: 0.45870143454521894\n",
      "epoch 319 out of 1000 loss: 0.37456569354981184\n",
      "epoch 329 out of 1000 loss: 0.4326880965381861\n",
      "epoch 339 out of 1000 loss: 0.4051711359061301\n",
      "epoch 349 out of 1000 loss: 0.37355274707078934\n",
      "epoch 359 out of 1000 loss: 0.5667175073176622\n",
      "epoch 369 out of 1000 loss: 0.4818479847162962\n",
      "epoch 379 out of 1000 loss: 0.4593395246192813\n",
      "epoch 389 out of 1000 loss: 0.38399582728743553\n",
      "epoch 399 out of 1000 loss: 0.552063588052988\n",
      "epoch 409 out of 1000 loss: 0.5182123947888613\n",
      "epoch 419 out of 1000 loss: 0.5186478681862354\n",
      "epoch 429 out of 1000 loss: 0.3902893392369151\n",
      "epoch 439 out of 1000 loss: 0.5499410228803754\n",
      "epoch 449 out of 1000 loss: 0.37222002632915974\n",
      "epoch 459 out of 1000 loss: 0.43333575688302517\n",
      "epoch 469 out of 1000 loss: 0.41692372178658843\n",
      "epoch 479 out of 1000 loss: 0.36429216247051954\n",
      "epoch 489 out of 1000 loss: 0.45910599641501904\n",
      "epoch 499 out of 1000 loss: 0.3851121701300144\n",
      "epoch 509 out of 1000 loss: 0.48737453296780586\n",
      "epoch 519 out of 1000 loss: 0.3943106490187347\n",
      "epoch 529 out of 1000 loss: 0.45236145704984665\n",
      "epoch 539 out of 1000 loss: 0.386857102625072\n",
      "epoch 549 out of 1000 loss: 0.401553962379694\n",
      "epoch 559 out of 1000 loss: 0.4170021307654679\n",
      "epoch 569 out of 1000 loss: 0.42767776595428586\n",
      "epoch 579 out of 1000 loss: 0.37991268560290337\n",
      "epoch 589 out of 1000 loss: 0.5666842982172966\n",
      "epoch 599 out of 1000 loss: 0.40500289015471935\n",
      "epoch 609 out of 1000 loss: 0.5696070697158575\n",
      "epoch 619 out of 1000 loss: 0.3812431644182652\n",
      "epoch 629 out of 1000 loss: 0.4473465932533145\n",
      "epoch 639 out of 1000 loss: 0.3838247274979949\n",
      "epoch 649 out of 1000 loss: 0.4592247297987342\n",
      "epoch 659 out of 1000 loss: 0.39741261303424835\n",
      "epoch 669 out of 1000 loss: 0.34595927502959967\n",
      "epoch 679 out of 1000 loss: 0.3860757334623486\n",
      "epoch 689 out of 1000 loss: 0.32903531193733215\n",
      "epoch 699 out of 1000 loss: 0.5267361924052238\n",
      "epoch 709 out of 1000 loss: 0.3854310321621597\n",
      "epoch 719 out of 1000 loss: 0.5652039963752031\n",
      "epoch 729 out of 1000 loss: 0.37734572123736143\n",
      "epoch 739 out of 1000 loss: 0.34481916250661016\n",
      "epoch 749 out of 1000 loss: 0.45591294579207897\n",
      "epoch 759 out of 1000 loss: 0.36948254331946373\n",
      "epoch 769 out of 1000 loss: 0.4264603713527322\n",
      "epoch 779 out of 1000 loss: 0.3928425097838044\n",
      "epoch 789 out of 1000 loss: 0.4238825784996152\n",
      "epoch 799 out of 1000 loss: 0.4361009346321225\n",
      "epoch 809 out of 1000 loss: 0.3443825226277113\n",
      "epoch 819 out of 1000 loss: 0.4030217342078686\n",
      "epoch 829 out of 1000 loss: 0.4674398694187403\n",
      "epoch 839 out of 1000 loss: 0.3727382104843855\n",
      "epoch 849 out of 1000 loss: 0.573319211602211\n",
      "epoch 859 out of 1000 loss: 0.40720769856125116\n",
      "epoch 869 out of 1000 loss: 0.390733833424747\n",
      "epoch 879 out of 1000 loss: 0.3686705231666565\n",
      "epoch 889 out of 1000 loss: 0.33979351073503494\n",
      "epoch 899 out of 1000 loss: 0.390248162439093\n",
      "epoch 909 out of 1000 loss: 0.37772652553394437\n",
      "epoch 919 out of 1000 loss: 0.41102951392531395\n",
      "epoch 929 out of 1000 loss: 0.500672816298902\n",
      "epoch 939 out of 1000 loss: 0.41670686565339565\n",
      "epoch 949 out of 1000 loss: 0.39451101422309875\n",
      "epoch 959 out of 1000 loss: 0.35558659955859184\n",
      "epoch 969 out of 1000 loss: 0.503750478848815\n",
      "epoch 979 out of 1000 loss: 0.3436929709278047\n",
      "epoch 989 out of 1000 loss: 0.3599891918711364\n",
      "epoch 999 out of 1000 loss: 0.3651251904666424\n",
      "run 1\n",
      "epoch 9 out of 1000 loss: 11.467189252376556\n",
      "epoch 19 out of 1000 loss: 8.613611042499542\n",
      "epoch 29 out of 1000 loss: 6.73304158449173\n",
      "epoch 39 out of 1000 loss: 6.121468424797058\n",
      "epoch 49 out of 1000 loss: 5.543438792228699\n",
      "epoch 59 out of 1000 loss: 2.100814640522003\n",
      "epoch 69 out of 1000 loss: 0.7221543528139591\n",
      "epoch 79 out of 1000 loss: 0.7851875051856041\n",
      "epoch 89 out of 1000 loss: 0.5203553717583418\n",
      "epoch 99 out of 1000 loss: 0.6845949403941631\n",
      "epoch 109 out of 1000 loss: 0.7022651433944702\n",
      "epoch 119 out of 1000 loss: 0.7418090924620628\n",
      "epoch 129 out of 1000 loss: 0.7636728547513485\n",
      "epoch 139 out of 1000 loss: 0.6276563294231892\n",
      "epoch 149 out of 1000 loss: 0.47682624123990536\n",
      "epoch 159 out of 1000 loss: 0.6424508132040501\n",
      "epoch 169 out of 1000 loss: 0.605471134185791\n",
      "epoch 179 out of 1000 loss: 0.5196520909667015\n",
      "epoch 189 out of 1000 loss: 0.5222834954038262\n",
      "epoch 199 out of 1000 loss: 0.6682382375001907\n",
      "epoch 209 out of 1000 loss: 0.4511245097965002\n",
      "epoch 219 out of 1000 loss: 0.41185983642935753\n",
      "epoch 229 out of 1000 loss: 0.4080403530970216\n",
      "epoch 239 out of 1000 loss: 0.4779021628201008\n",
      "epoch 249 out of 1000 loss: 0.5986696965992451\n",
      "epoch 259 out of 1000 loss: 0.43888186663389206\n",
      "epoch 269 out of 1000 loss: 0.48628221452236176\n",
      "epoch 279 out of 1000 loss: 0.46411815751343966\n",
      "epoch 289 out of 1000 loss: 0.40972424298524857\n",
      "epoch 299 out of 1000 loss: 0.545727202668786\n",
      "epoch 309 out of 1000 loss: 0.3791386391967535\n",
      "epoch 319 out of 1000 loss: 0.45367696322500706\n",
      "epoch 329 out of 1000 loss: 0.35193016566336155\n",
      "epoch 339 out of 1000 loss: 0.3617560137063265\n",
      "epoch 349 out of 1000 loss: 0.434953018091619\n",
      "epoch 359 out of 1000 loss: 0.3734505991451442\n",
      "epoch 369 out of 1000 loss: 0.3933632834814489\n",
      "epoch 379 out of 1000 loss: 0.536971602588892\n",
      "epoch 389 out of 1000 loss: 0.5382956955581903\n",
      "epoch 399 out of 1000 loss: 0.4123352747410536\n",
      "epoch 409 out of 1000 loss: 0.4620090792886913\n",
      "epoch 419 out of 1000 loss: 0.564112139865756\n",
      "epoch 429 out of 1000 loss: 0.40158734004944563\n",
      "epoch 439 out of 1000 loss: 0.46509660221636295\n",
      "epoch 449 out of 1000 loss: 0.522531408816576\n",
      "epoch 459 out of 1000 loss: 0.40806954354047775\n",
      "epoch 469 out of 1000 loss: 0.5270109605044127\n",
      "epoch 479 out of 1000 loss: 0.426127846352756\n",
      "epoch 489 out of 1000 loss: 0.5071315243840218\n",
      "epoch 499 out of 1000 loss: 0.3874878454953432\n",
      "epoch 509 out of 1000 loss: 0.568217696622014\n",
      "epoch 519 out of 1000 loss: 0.46624807734042406\n",
      "epoch 529 out of 1000 loss: 0.46903460193425417\n",
      "epoch 539 out of 1000 loss: 0.4802660867571831\n",
      "epoch 549 out of 1000 loss: 0.3888633903115988\n",
      "epoch 559 out of 1000 loss: 0.3642628947272897\n",
      "epoch 569 out of 1000 loss: 0.36843666434288025\n",
      "epoch 579 out of 1000 loss: 0.3567834091372788\n",
      "epoch 589 out of 1000 loss: 0.4159073308110237\n",
      "epoch 599 out of 1000 loss: 0.3758127801120281\n",
      "epoch 609 out of 1000 loss: 0.4223940521478653\n",
      "epoch 619 out of 1000 loss: 0.3737423876300454\n",
      "epoch 629 out of 1000 loss: 0.3830604450777173\n",
      "epoch 639 out of 1000 loss: 0.363370050676167\n",
      "epoch 649 out of 1000 loss: 0.38861952954903245\n",
      "epoch 659 out of 1000 loss: 0.37819709861651063\n",
      "epoch 669 out of 1000 loss: 0.4307147820945829\n",
      "epoch 679 out of 1000 loss: 0.4032773971557617\n",
      "epoch 689 out of 1000 loss: 0.42014339566230774\n",
      "epoch 699 out of 1000 loss: 0.3805038779973984\n",
      "epoch 709 out of 1000 loss: 0.4621102958917618\n",
      "epoch 719 out of 1000 loss: 0.3518366515636444\n",
      "epoch 729 out of 1000 loss: 0.3635793458670378\n",
      "epoch 739 out of 1000 loss: 0.38103470858186483\n",
      "epoch 749 out of 1000 loss: 0.39418982388451695\n",
      "epoch 759 out of 1000 loss: 0.5209052171558142\n",
      "epoch 769 out of 1000 loss: 0.41890894435346127\n",
      "epoch 779 out of 1000 loss: 0.39086886076256633\n",
      "epoch 789 out of 1000 loss: 0.3824704997241497\n",
      "epoch 799 out of 1000 loss: 0.4566440787166357\n",
      "epoch 809 out of 1000 loss: 0.38266140408813953\n",
      "epoch 819 out of 1000 loss: 0.40550049440935254\n",
      "epoch 829 out of 1000 loss: 0.3571404875256121\n",
      "epoch 839 out of 1000 loss: 0.3655831371434033\n",
      "epoch 849 out of 1000 loss: 0.4398609781637788\n",
      "epoch 859 out of 1000 loss: 0.4824260286986828\n",
      "epoch 869 out of 1000 loss: 0.4188585178926587\n",
      "epoch 879 out of 1000 loss: 0.374062473885715\n",
      "epoch 889 out of 1000 loss: 0.3359903101809323\n",
      "epoch 899 out of 1000 loss: 0.4004052169620991\n",
      "epoch 909 out of 1000 loss: 0.3405778887681663\n",
      "epoch 919 out of 1000 loss: 0.4055922096595168\n",
      "epoch 929 out of 1000 loss: 0.3160191171336919\n",
      "epoch 939 out of 1000 loss: 0.34087112406268716\n",
      "epoch 949 out of 1000 loss: 0.34724763687700033\n",
      "epoch 959 out of 1000 loss: 0.4328041113913059\n",
      "epoch 969 out of 1000 loss: 0.38306015031412244\n",
      "epoch 979 out of 1000 loss: 0.43830421660095453\n",
      "epoch 989 out of 1000 loss: 0.4009849727153778\n",
      "epoch 999 out of 1000 loss: 0.4181356765329838\n",
      "run 2\n",
      "epoch 9 out of 1000 loss: 8.038101077079773\n",
      "epoch 19 out of 1000 loss: 6.361452132463455\n",
      "epoch 29 out of 1000 loss: 6.028855979442596\n",
      "epoch 39 out of 1000 loss: 5.900520712137222\n",
      "epoch 49 out of 1000 loss: 5.710843622684479\n",
      "epoch 59 out of 1000 loss: 5.364667296409607\n",
      "epoch 69 out of 1000 loss: 3.1345567852258682\n",
      "epoch 79 out of 1000 loss: 0.8880678042769432\n",
      "epoch 89 out of 1000 loss: 0.6527609582990408\n",
      "epoch 99 out of 1000 loss: 0.535689658485353\n",
      "epoch 109 out of 1000 loss: 1.0762212201952934\n",
      "epoch 119 out of 1000 loss: 0.48095003236085176\n",
      "epoch 129 out of 1000 loss: 0.5276118088513613\n",
      "epoch 139 out of 1000 loss: 0.47727242298424244\n",
      "epoch 149 out of 1000 loss: 0.7984744217246771\n",
      "epoch 159 out of 1000 loss: 0.49597644340246916\n",
      "epoch 169 out of 1000 loss: 0.4854391496628523\n",
      "epoch 179 out of 1000 loss: 0.5550227425992489\n",
      "epoch 189 out of 1000 loss: 0.6789785549044609\n",
      "epoch 199 out of 1000 loss: 0.5326331690885127\n",
      "epoch 209 out of 1000 loss: 0.4531018026173115\n",
      "epoch 219 out of 1000 loss: 0.40499054407700896\n",
      "epoch 229 out of 1000 loss: 0.38557632220909\n",
      "epoch 239 out of 1000 loss: 0.46564625203609467\n",
      "epoch 249 out of 1000 loss: 0.6009130775928497\n",
      "epoch 259 out of 1000 loss: 0.43935083597898483\n",
      "epoch 269 out of 1000 loss: 0.5557985957711935\n",
      "epoch 279 out of 1000 loss: 0.45696972217410803\n",
      "epoch 289 out of 1000 loss: 0.3905059425160289\n",
      "epoch 299 out of 1000 loss: 0.4537945184856653\n",
      "epoch 309 out of 1000 loss: 0.4430847689509392\n",
      "epoch 319 out of 1000 loss: 0.49873250164091587\n",
      "epoch 329 out of 1000 loss: 0.4294665474444628\n",
      "epoch 339 out of 1000 loss: 0.46668021008372307\n",
      "epoch 349 out of 1000 loss: 0.511184548959136\n",
      "epoch 359 out of 1000 loss: 0.449806934222579\n",
      "epoch 369 out of 1000 loss: 0.5336613673716784\n",
      "epoch 379 out of 1000 loss: 0.4123855661600828\n",
      "epoch 389 out of 1000 loss: 0.42177892103791237\n",
      "epoch 399 out of 1000 loss: 0.512589979916811\n",
      "epoch 409 out of 1000 loss: 0.3939472916536033\n",
      "epoch 419 out of 1000 loss: 0.3971604844555259\n",
      "epoch 429 out of 1000 loss: 0.42179916636087\n",
      "epoch 439 out of 1000 loss: 0.4643804538063705\n",
      "epoch 449 out of 1000 loss: 0.6722655817866325\n",
      "epoch 459 out of 1000 loss: 0.4966875948011875\n",
      "epoch 469 out of 1000 loss: 0.43827485479414463\n",
      "epoch 479 out of 1000 loss: 0.6586719211190939\n",
      "epoch 489 out of 1000 loss: 0.3970603384077549\n",
      "epoch 499 out of 1000 loss: 0.38894891645759344\n",
      "epoch 509 out of 1000 loss: 0.40623475704342127\n",
      "epoch 519 out of 1000 loss: 0.4344166973605752\n",
      "epoch 529 out of 1000 loss: 0.4376026336103678\n",
      "epoch 539 out of 1000 loss: 0.3798637720756233\n",
      "epoch 549 out of 1000 loss: 0.38502932246774435\n",
      "epoch 559 out of 1000 loss: 0.37173263635486364\n",
      "epoch 569 out of 1000 loss: 0.420666023157537\n",
      "epoch 579 out of 1000 loss: 0.4714744910597801\n",
      "epoch 589 out of 1000 loss: 0.4708770867437124\n",
      "epoch 599 out of 1000 loss: 0.3877502507530153\n",
      "epoch 609 out of 1000 loss: 0.3775297487154603\n",
      "epoch 619 out of 1000 loss: 0.39040924794971943\n",
      "epoch 629 out of 1000 loss: 0.3868265263736248\n",
      "epoch 639 out of 1000 loss: 0.3966302676126361\n",
      "epoch 649 out of 1000 loss: 0.39544341526925564\n",
      "epoch 659 out of 1000 loss: 0.3694831395987421\n",
      "epoch 669 out of 1000 loss: 0.3629699090961367\n",
      "epoch 679 out of 1000 loss: 0.41469145752489567\n",
      "epoch 689 out of 1000 loss: 0.5263819890096784\n",
      "epoch 699 out of 1000 loss: 0.4022891893982887\n",
      "epoch 709 out of 1000 loss: 0.4634906742721796\n",
      "epoch 719 out of 1000 loss: 0.5269483048468828\n",
      "epoch 729 out of 1000 loss: 0.3462352624628693\n",
      "epoch 739 out of 1000 loss: 0.3889535451307893\n",
      "epoch 749 out of 1000 loss: 0.36946808034554124\n",
      "epoch 759 out of 1000 loss: 0.4558138083666563\n",
      "epoch 769 out of 1000 loss: 0.456609146669507\n",
      "epoch 779 out of 1000 loss: 0.3578085647895932\n",
      "epoch 789 out of 1000 loss: 0.35896141082048416\n",
      "epoch 799 out of 1000 loss: 0.4007678865455091\n",
      "epoch 809 out of 1000 loss: 0.41365467198193073\n",
      "epoch 819 out of 1000 loss: 0.3502558749169111\n",
      "epoch 829 out of 1000 loss: 0.36487282160669565\n",
      "epoch 839 out of 1000 loss: 0.49583457689732313\n",
      "epoch 849 out of 1000 loss: 0.3358264740090817\n",
      "epoch 859 out of 1000 loss: 0.38173830788582563\n",
      "epoch 869 out of 1000 loss: 0.36441837158054113\n",
      "epoch 879 out of 1000 loss: 0.4028747910633683\n",
      "epoch 889 out of 1000 loss: 0.4707983750849962\n",
      "epoch 899 out of 1000 loss: 0.4346761107444763\n",
      "epoch 909 out of 1000 loss: 0.36328878439962864\n",
      "epoch 919 out of 1000 loss: 0.37690954096615314\n",
      "epoch 929 out of 1000 loss: 0.3338743350468576\n",
      "epoch 939 out of 1000 loss: 0.36115532694384456\n",
      "epoch 949 out of 1000 loss: 0.4430395159870386\n",
      "epoch 959 out of 1000 loss: 0.47193117439746857\n",
      "epoch 969 out of 1000 loss: 0.3351608132943511\n",
      "epoch 979 out of 1000 loss: 0.4151817699894309\n",
      "epoch 989 out of 1000 loss: 0.3642697539180517\n",
      "epoch 999 out of 1000 loss: 0.32406992837786674\n",
      "run 3\n",
      "epoch 9 out of 1000 loss: 10.16382920742035\n",
      "epoch 19 out of 1000 loss: 7.975315451622009\n",
      "epoch 29 out of 1000 loss: 6.338050067424774\n",
      "epoch 39 out of 1000 loss: 5.559391468763351\n",
      "epoch 49 out of 1000 loss: 1.3537709340453148\n",
      "epoch 59 out of 1000 loss: 1.1133108511567116\n",
      "epoch 69 out of 1000 loss: 0.6894366936758161\n",
      "epoch 79 out of 1000 loss: 0.6196607332676649\n",
      "epoch 89 out of 1000 loss: 0.5381573680788279\n",
      "epoch 99 out of 1000 loss: 0.47839527390897274\n",
      "epoch 109 out of 1000 loss: 0.789872458204627\n",
      "epoch 119 out of 1000 loss: 0.7963364087045193\n",
      "epoch 129 out of 1000 loss: 0.5092709399759769\n",
      "epoch 139 out of 1000 loss: 0.7649206928908825\n",
      "epoch 149 out of 1000 loss: 0.5064089372754097\n",
      "epoch 159 out of 1000 loss: 0.41822046134620905\n",
      "epoch 169 out of 1000 loss: 0.4730397234670818\n",
      "epoch 179 out of 1000 loss: 0.6051425095647573\n",
      "epoch 189 out of 1000 loss: 0.5040078219026327\n",
      "epoch 199 out of 1000 loss: 0.5913192816078663\n",
      "epoch 209 out of 1000 loss: 0.39899549447000027\n",
      "epoch 219 out of 1000 loss: 0.3991229645907879\n",
      "epoch 229 out of 1000 loss: 0.6863728202879429\n",
      "epoch 239 out of 1000 loss: 0.40915422514081\n",
      "epoch 249 out of 1000 loss: 0.4694781480357051\n",
      "epoch 259 out of 1000 loss: 0.5218923827633262\n",
      "epoch 269 out of 1000 loss: 0.38911555893719196\n",
      "epoch 279 out of 1000 loss: 0.4475610386580229\n",
      "epoch 289 out of 1000 loss: 0.442671000957489\n",
      "epoch 299 out of 1000 loss: 0.5799378305673599\n",
      "epoch 309 out of 1000 loss: 0.38247783947736025\n",
      "epoch 319 out of 1000 loss: 0.420179002918303\n",
      "epoch 329 out of 1000 loss: 0.3792088571935892\n",
      "epoch 339 out of 1000 loss: 0.4271719390526414\n",
      "epoch 349 out of 1000 loss: 0.5760612189769745\n",
      "epoch 359 out of 1000 loss: 0.39561631716787815\n",
      "epoch 369 out of 1000 loss: 0.3752253847196698\n",
      "epoch 379 out of 1000 loss: 0.43847096897661686\n",
      "epoch 389 out of 1000 loss: 0.5154381841421127\n",
      "epoch 399 out of 1000 loss: 0.4798618983477354\n",
      "epoch 409 out of 1000 loss: 0.475202988833189\n",
      "epoch 419 out of 1000 loss: 0.5697685517370701\n",
      "epoch 429 out of 1000 loss: 0.40652708150446415\n",
      "epoch 439 out of 1000 loss: 0.4317881427705288\n",
      "epoch 449 out of 1000 loss: 0.46279315929859877\n",
      "epoch 459 out of 1000 loss: 0.43592220544815063\n",
      "epoch 469 out of 1000 loss: 0.4406506987288594\n",
      "epoch 479 out of 1000 loss: 0.43024560809135437\n",
      "epoch 489 out of 1000 loss: 0.3536646505817771\n",
      "epoch 499 out of 1000 loss: 0.41199185885488987\n",
      "epoch 509 out of 1000 loss: 0.5520684029906988\n",
      "epoch 519 out of 1000 loss: 0.38046196661889553\n",
      "epoch 529 out of 1000 loss: 0.3898528744466603\n",
      "epoch 539 out of 1000 loss: 0.36005157604813576\n",
      "epoch 549 out of 1000 loss: 0.4564874144271016\n",
      "epoch 559 out of 1000 loss: 0.5295362900942564\n",
      "epoch 569 out of 1000 loss: 0.39274054067209363\n",
      "epoch 579 out of 1000 loss: 0.6339705660939217\n",
      "epoch 589 out of 1000 loss: 0.49071439914405346\n",
      "epoch 599 out of 1000 loss: 0.4967753440141678\n",
      "epoch 609 out of 1000 loss: 0.38627658784389496\n",
      "epoch 619 out of 1000 loss: 0.3436767151579261\n",
      "epoch 629 out of 1000 loss: 0.47247529216110706\n",
      "epoch 639 out of 1000 loss: 0.5394628485664725\n",
      "epoch 649 out of 1000 loss: 0.54058020375669\n",
      "epoch 659 out of 1000 loss: 0.5881279110908508\n",
      "epoch 669 out of 1000 loss: 0.3843346247449517\n",
      "epoch 679 out of 1000 loss: 0.4383816262707114\n",
      "epoch 689 out of 1000 loss: 0.3594823172315955\n",
      "epoch 699 out of 1000 loss: 0.48657893016934395\n",
      "epoch 709 out of 1000 loss: 0.3879344407469034\n",
      "epoch 719 out of 1000 loss: 0.3885093368589878\n",
      "epoch 729 out of 1000 loss: 0.43883341923356056\n",
      "epoch 739 out of 1000 loss: 0.4189184680581093\n",
      "epoch 749 out of 1000 loss: 0.40096405940130353\n",
      "epoch 759 out of 1000 loss: 0.34849501494318247\n",
      "epoch 769 out of 1000 loss: 0.3904144992120564\n",
      "epoch 779 out of 1000 loss: 0.38403401197865605\n",
      "epoch 789 out of 1000 loss: 0.46327310986816883\n",
      "epoch 799 out of 1000 loss: 0.37948760855942965\n",
      "epoch 809 out of 1000 loss: 0.3377223666757345\n",
      "epoch 819 out of 1000 loss: 0.34881469840183854\n",
      "epoch 829 out of 1000 loss: 0.44389384612441063\n",
      "epoch 839 out of 1000 loss: 0.3759415587410331\n",
      "epoch 849 out of 1000 loss: 0.4369657076895237\n",
      "epoch 859 out of 1000 loss: 0.3609111262485385\n",
      "epoch 869 out of 1000 loss: 0.4190209056250751\n",
      "epoch 879 out of 1000 loss: 0.3398092081770301\n",
      "epoch 889 out of 1000 loss: 0.35750184394419193\n",
      "epoch 899 out of 1000 loss: 0.40861297212541103\n",
      "epoch 909 out of 1000 loss: 0.40305382013320923\n",
      "epoch 919 out of 1000 loss: 0.43098285235464573\n",
      "epoch 929 out of 1000 loss: 0.3825201843865216\n",
      "epoch 939 out of 1000 loss: 0.41004803124815226\n",
      "epoch 949 out of 1000 loss: 0.37537964270450175\n",
      "epoch 959 out of 1000 loss: 0.3900453904643655\n",
      "epoch 969 out of 1000 loss: 0.3745999736711383\n",
      "epoch 979 out of 1000 loss: 0.33202544250525534\n",
      "epoch 989 out of 1000 loss: 0.38317121379077435\n",
      "epoch 999 out of 1000 loss: 0.39778652787208557\n",
      "run 4\n",
      "epoch 9 out of 1000 loss: 10.97186529636383\n",
      "epoch 19 out of 1000 loss: 8.799712717533112\n",
      "epoch 29 out of 1000 loss: 6.8274635672569275\n",
      "epoch 39 out of 1000 loss: 6.152045518159866\n",
      "epoch 49 out of 1000 loss: 5.705996990203857\n",
      "epoch 59 out of 1000 loss: 2.8206574469804764\n",
      "epoch 69 out of 1000 loss: 1.013261891901493\n",
      "epoch 79 out of 1000 loss: 0.9052242953330278\n",
      "epoch 89 out of 1000 loss: 0.6832192912697792\n",
      "epoch 99 out of 1000 loss: 0.7962003406137228\n",
      "epoch 109 out of 1000 loss: 0.5372920660302043\n",
      "epoch 119 out of 1000 loss: 0.7121959179639816\n",
      "epoch 129 out of 1000 loss: 0.7078623529523611\n",
      "epoch 139 out of 1000 loss: 0.648755956441164\n",
      "epoch 149 out of 1000 loss: 0.6277556847780943\n",
      "epoch 159 out of 1000 loss: 0.6379864811897278\n",
      "epoch 169 out of 1000 loss: 0.5824660919606686\n",
      "epoch 179 out of 1000 loss: 0.6261130329221487\n",
      "epoch 189 out of 1000 loss: 0.5729680433869362\n",
      "epoch 199 out of 1000 loss: 0.5772923156619072\n",
      "epoch 209 out of 1000 loss: 0.5693210493773222\n",
      "epoch 219 out of 1000 loss: 0.5569909326732159\n",
      "epoch 229 out of 1000 loss: 0.548907807096839\n",
      "epoch 239 out of 1000 loss: 0.5583197986707091\n",
      "epoch 249 out of 1000 loss: 0.5501805394887924\n",
      "epoch 259 out of 1000 loss: 0.41984413377940655\n",
      "epoch 269 out of 1000 loss: 0.5356025099754333\n",
      "epoch 279 out of 1000 loss: 0.500462694093585\n",
      "epoch 289 out of 1000 loss: 0.5857263710349798\n",
      "epoch 299 out of 1000 loss: 0.5162753146141768\n",
      "epoch 309 out of 1000 loss: 0.4586838958784938\n",
      "epoch 319 out of 1000 loss: 0.6200263760983944\n",
      "epoch 329 out of 1000 loss: 0.4901427533477545\n",
      "epoch 339 out of 1000 loss: 0.5492418967187405\n",
      "epoch 349 out of 1000 loss: 0.5330500490963459\n",
      "epoch 359 out of 1000 loss: 0.4941273592412472\n",
      "epoch 369 out of 1000 loss: 0.4538767645135522\n",
      "epoch 379 out of 1000 loss: 0.47881707176566124\n",
      "epoch 389 out of 1000 loss: 0.47383419843390584\n",
      "epoch 399 out of 1000 loss: 0.41677604150027037\n",
      "epoch 409 out of 1000 loss: 0.4283568300306797\n",
      "epoch 419 out of 1000 loss: 0.4578451570123434\n",
      "epoch 429 out of 1000 loss: 0.5332829672843218\n",
      "epoch 439 out of 1000 loss: 0.47170119639486074\n",
      "epoch 449 out of 1000 loss: 0.6632724720984697\n",
      "epoch 459 out of 1000 loss: 0.5537884160876274\n",
      "epoch 469 out of 1000 loss: 0.41701364424079657\n",
      "epoch 479 out of 1000 loss: 0.5481844916939735\n",
      "epoch 489 out of 1000 loss: 0.43776329746469855\n",
      "epoch 499 out of 1000 loss: 0.5563294515013695\n",
      "epoch 509 out of 1000 loss: 0.4582842327654362\n",
      "epoch 519 out of 1000 loss: 0.3830224983394146\n",
      "epoch 529 out of 1000 loss: 0.5550213605165482\n",
      "epoch 539 out of 1000 loss: 0.44629013538360596\n",
      "epoch 549 out of 1000 loss: 0.5006625354290009\n",
      "epoch 559 out of 1000 loss: 0.4439436485990882\n",
      "epoch 569 out of 1000 loss: 0.5128489304333925\n",
      "epoch 579 out of 1000 loss: 0.5137729179114103\n",
      "epoch 589 out of 1000 loss: 0.3951002461835742\n",
      "epoch 599 out of 1000 loss: 0.4295150078833103\n",
      "epoch 609 out of 1000 loss: 0.4798435512930155\n",
      "epoch 619 out of 1000 loss: 0.4411383429542184\n",
      "epoch 629 out of 1000 loss: 0.4612412629649043\n",
      "epoch 639 out of 1000 loss: 0.5107941552996635\n",
      "epoch 649 out of 1000 loss: 0.43361576460301876\n",
      "epoch 659 out of 1000 loss: 0.5726039372384548\n",
      "epoch 669 out of 1000 loss: 0.39934460120275617\n",
      "epoch 679 out of 1000 loss: 0.4014247739687562\n",
      "epoch 689 out of 1000 loss: 0.49131617695093155\n",
      "epoch 699 out of 1000 loss: 0.4363942416384816\n",
      "epoch 709 out of 1000 loss: 0.40163818560540676\n",
      "epoch 719 out of 1000 loss: 0.38741181371733546\n",
      "epoch 729 out of 1000 loss: 0.4216829827055335\n",
      "epoch 739 out of 1000 loss: 0.4180069016292691\n",
      "epoch 749 out of 1000 loss: 0.4908735528588295\n",
      "epoch 759 out of 1000 loss: 0.5122495125979185\n",
      "epoch 769 out of 1000 loss: 0.4938641535118222\n",
      "epoch 779 out of 1000 loss: 0.4717315174639225\n",
      "epoch 789 out of 1000 loss: 0.37061220360919833\n",
      "epoch 799 out of 1000 loss: 0.40940179536119103\n",
      "epoch 809 out of 1000 loss: 0.48994934745132923\n",
      "epoch 819 out of 1000 loss: 0.4697601292282343\n",
      "epoch 829 out of 1000 loss: 0.4259567125700414\n",
      "epoch 839 out of 1000 loss: 0.3568241447210312\n",
      "epoch 849 out of 1000 loss: 0.3540789200924337\n",
      "epoch 859 out of 1000 loss: 0.4302327986806631\n",
      "epoch 869 out of 1000 loss: 0.38948140013962984\n",
      "epoch 879 out of 1000 loss: 0.38731880858540535\n",
      "epoch 889 out of 1000 loss: 0.420418718829751\n",
      "epoch 899 out of 1000 loss: 0.3706766967661679\n",
      "epoch 909 out of 1000 loss: 0.4029092362616211\n",
      "epoch 919 out of 1000 loss: 0.4720128942281008\n",
      "epoch 929 out of 1000 loss: 0.3597948355600238\n",
      "epoch 939 out of 1000 loss: 0.37842137925326824\n",
      "epoch 949 out of 1000 loss: 0.44218289852142334\n",
      "epoch 959 out of 1000 loss: 0.372415934689343\n",
      "epoch 969 out of 1000 loss: 0.38555279187858105\n",
      "epoch 979 out of 1000 loss: 0.33614344033412635\n",
      "epoch 989 out of 1000 loss: 0.34093495598062873\n",
      "epoch 999 out of 1000 loss: 0.36577643267810345\n",
      "mae mean: 0.028559649363160133 std: 0.00010577673674561083\n",
      "mse mean: 0.008029094897210598 std: 2.8942880817339756e-05\n",
      "mape mean: 0.037558577954769135 std: 0.0036490298807621002\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"K6eVohRwyVyqrEMKyG3u78"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## MSELoss (Original Loss Function)"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"yxo54soG2tmV86IbK8p9uB"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def create_model():\n",
    "    model = torch.nn.Sequential(nn.Linear(7, 16),\n",
    "                            nn.Linear(16,32),\n",
    "                            nn.Linear(32, 64),\n",
    "                            nn.Sigmoid(),\n",
    "                            nn.Linear(64,10),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(10,1),\n",
    "                            nn.Sigmoid()\n",
    "                            )\n",
    "    return model\n",
    "\n",
    "model_params = {\n",
    "    'train_loader': train_loader,\n",
    "    'test_features': test_features,\n",
    "    'test_target': test_target,\n",
    "    'create_model': create_model,\n",
    "    'n_epochs': n_epochs,\n",
    "    'criterion': nn.MSELoss(),\n",
    "    'init_fn': weights_init_uniform\n",
    "}\n",
    "\n",
    "run_n(5, model_params)"
   ],
   "execution_count":9,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "run 0\n",
      "epoch 9 out of 100 loss: 0.1449949226807803\n",
      "epoch 19 out of 100 loss: 0.12046138982987031\n",
      "epoch 29 out of 100 loss: 0.11575134488521144\n",
      "epoch 39 out of 100 loss: 0.11217760978615843\n",
      "epoch 49 out of 100 loss: 0.09994395257672295\n",
      "epoch 59 out of 100 loss: 0.09769393512397073\n",
      "epoch 69 out of 100 loss: 0.09634557861136273\n",
      "epoch 79 out of 100 loss: 0.09599288564641029\n",
      "epoch 89 out of 100 loss: 0.0957610290060984\n",
      "epoch 99 out of 100 loss: 0.09556683435221203\n",
      "run 1\n",
      "epoch 9 out of 100 loss: 0.14744093123590574\n",
      "epoch 19 out of 100 loss: 0.12152450327994302\n",
      "epoch 29 out of 100 loss: 0.11054960888577625\n",
      "epoch 39 out of 100 loss: 0.10614472102315631\n",
      "epoch 49 out of 100 loss: 0.10311789468687493\n",
      "epoch 59 out of 100 loss: 0.09714487944438588\n",
      "epoch 69 out of 100 loss: 0.09638750302838162\n",
      "epoch 79 out of 100 loss: 0.09567401972890366\n",
      "epoch 89 out of 100 loss: 0.09543857791868504\n",
      "epoch 99 out of 100 loss: 0.09528265755943721\n",
      "run 2\n",
      "epoch 9 out of 100 loss: 0.12627828409313224\n",
      "epoch 19 out of 100 loss: 0.1044388072041329\n",
      "epoch 29 out of 100 loss: 0.1019199081347324\n",
      "epoch 39 out of 100 loss: 0.10066131391795352\n",
      "epoch 49 out of 100 loss: 0.09867428199504502\n",
      "epoch 59 out of 100 loss: 0.09792083108914085\n",
      "epoch 69 out of 100 loss: 0.09730726611451246\n",
      "epoch 79 out of 100 loss: 0.0966398293239763\n",
      "epoch 89 out of 100 loss: 0.09616838984220522\n",
      "epoch 99 out of 100 loss: 0.09572496259352192\n",
      "run 3\n",
      "epoch 9 out of 100 loss: 0.2948245476000011\n",
      "epoch 19 out of 100 loss: 0.14242686750367284\n",
      "epoch 29 out of 100 loss: 0.1276423567906022\n",
      "epoch 39 out of 100 loss: 0.11778911133296788\n",
      "epoch 49 out of 100 loss: 0.11158298153895885\n",
      "epoch 59 out of 100 loss: 0.10807031858712435\n",
      "epoch 69 out of 100 loss: 0.1058133186888881\n",
      "epoch 79 out of 100 loss: 0.10280321660684422\n",
      "epoch 89 out of 100 loss: 0.09788139487500302\n",
      "epoch 99 out of 100 loss: 0.09708431319450028\n",
      "run 4\n",
      "epoch 9 out of 100 loss: 0.130839510995429\n",
      "epoch 19 out of 100 loss: 0.11407582473475486\n",
      "epoch 29 out of 100 loss: 0.10259533699718304\n",
      "epoch 39 out of 100 loss: 0.10107584210345522\n",
      "epoch 49 out of 100 loss: 0.1002288313175086\n",
      "epoch 59 out of 100 loss: 0.09966218698536977\n",
      "epoch 69 out of 100 loss: 0.0991996958910022\n",
      "epoch 79 out of 100 loss: 0.09880064422031865\n",
      "epoch 89 out of 100 loss: 0.09844124043593183\n",
      "epoch 99 out of 100 loss: 0.0980889868515078\n",
      "mae mean: 0.03711101412773132 std: 0.002717087045311928\n",
      "mse mean: 0.008002342656254768 std: 8.412005263380706e-05\n",
      "mape mean: 0.3100283741950989 std: 0.05855955928564072\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"01Pnn7V9ophzgrCTaprAzQ"
    }
   }
  }
 ],
 "metadata":{
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}